# RAG Mental Health

A Retrieval-Augmented Generation (RAG) system for mental health support using multiple LLM backends (Ollama, OpenAI, Gemini) with advanced prompt engineering and evaluation capabilities.

---

## Project Architectural Structure

```
rag-mental-health/
â”œâ”€â”€ ğŸ“„ Configuration & Documentation
â”‚   â”œâ”€â”€ README.md                    # Main documentation and usage guide
â”‚   â”œâ”€â”€ PROJECT_REVIEW.md            # Technical review and analysis
â”‚   â”œâ”€â”€ pyproject.toml               # Project metadata and dependencies
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â””â”€â”€ .gitignore                   # Git ignore patterns
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ User Interface
â”‚   â””â”€â”€ app_streamlit.py             # Advanced Streamlit UI (502 lines)
â”‚
â”œâ”€â”€ ğŸ“Š Data Pipeline
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ ğŸ“„ Raw Data Sources
â”‚       â”‚   â”œâ”€â”€ counselchat/         # Professional therapist responses
â”‚       â”‚   â”œâ”€â”€ reddit/              # Community discussions
â”‚       â”‚   â”œâ”€â”€ mind/                # Mind.org.uk resources
â”‚       â”‚   â”œâ”€â”€ pubmed/              # Medical research papers
â”‚       â”‚   â””â”€â”€ who/                 # WHO mental health guidelines
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ Processed Data
â”‚       â”‚   â”œâ”€â”€ chunks/              # Text chunks for RAG
â”‚       â”‚   â”œâ”€â”€ embeddings/          # Vector embeddings
â”‚       â”‚   â””â”€â”€ vectordb/            # ChromaDB vector database
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ Evaluation Data
â”‚       â”‚   â”œâ”€â”€ evaluations/         # User evaluations and metrics
â”‚       â”‚   â””â”€â”€ logs/                # Interaction logs
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“ Documentation
â”‚           â””â”€â”€ docs/                # Reference documents
â”‚
â”œâ”€â”€ ğŸ”§ Core RAG Engine (src/ragmh/)
â”‚   â”œâ”€â”€ __init__.py                  # Package exports
â”‚   â”œâ”€â”€ __main__.py                  # CLI entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”„ Data Processing
â”‚   â”‚   â”œâ”€â”€ ingest.py                # Data ingestion (376 lines)
â”‚   â”‚   â”œâ”€â”€ chunk.py                 # Text chunking (306 lines)
â”‚   â”‚   â””â”€â”€ embed.py                 # Embedding generation (242 lines)
â”‚   â”‚
â”‚   â”œâ”€â”€ ï¿½ï¿½ AI/ML Components
â”‚   â”‚   â”œâ”€â”€ llm.py                   # LLM backends (167 lines)
â”‚   â”‚   â”œâ”€â”€ vanilla_llm.py           # Vanilla LLM comparison (196 lines)
â”‚   â”‚   â””â”€â”€ response_quality.py      # Response quality metrics (22 lines)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ” Retrieval & Storage
â”‚   â”‚   â”œâ”€â”€ vectordb.py              # ChromaDB operations (342 lines)
â”‚   â”‚   â””â”€â”€ quick_rag_fixes.py      # RAG enhancements (277 lines)
â”‚   â”‚
â”‚   â”œâ”€â”€ âš¡ Core Pipeline
â”‚   â”‚   â”œâ”€â”€ chains.py                # Main RAG pipeline (188 lines)
â”‚   â”‚   â””â”€â”€ config.py                # Configuration management (25 lines)
â”‚   â”‚
â”‚   â”œâ”€â”€ ï¿½ï¿½ï¸ Interface
â”‚   â”‚   â”œâ”€â”€ cli.py                   # Command-line interface (217 lines)
â”‚   â”‚   â””â”€â”€ enhanced_prompts.py      # Advanced prompts (0 lines)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ§ª Testing & Evaluation
â”‚       â””â”€â”€ tests/
â”‚           â””â”€â”€ eval_pipeline.py     # Automated evaluation (329 lines)
â”‚
â””â”€â”€ ï¿½ï¿½ï¸ Utilities
    â””â”€â”€ scripts/
        â”œâ”€â”€ build_index.py           # Vector index builder (53 lines)
        â”œâ”€â”€ generate_eval_data.py    # Evaluation data generator (344 lines)
        â””â”€â”€ test_improvements.py     # Improvement testing (23 lines)
```


### Pipeline Overview
1. **Ingestion**: Download and preprocess mental health data from multiple sources.
2. **Chunking**: Split documents into semantically meaningful chunks.
3. **Embedding**: Generate vector embeddings for all chunks.
4. **Indexing**: Store chunks and embeddings in ChromaDB for fast retrieval.
5. **Retrieval**: Given a user query, retrieve relevant chunks (vector search + cross-encoder rerank).
6. **Prompting**: Build a context-rich prompt for the LLM using enhanced templates.
7. **Generation**: Generate a response using Ollama, OpenAI, or Gemini LLMs.
8. **Post-processing**: Polish the response for empathy, safety, and actionable advice.
9. **Evaluation**: Analyze system outputs for semantic similarity, context relevance, and toxicity.

---

## Prerequisites
- Python 3.8+
- Ollama installed (for local LLM)
- 8GB RAM minimum (more recommended for large models)
- (Optional) OpenAI and Gemini API keys for cloud LLMs

## Setup Instructions

### 1. Clone the Repository
```sh
git clone https://github.com/mfarvaresh/rag-mental-health.git
cd rag-mental-health
```

### 2. Install Ollama
Download from: https://ollama.com/download

### 3. Pull phi3 model (or other supported models)
```sh
ollama pull phi3:mini
```

### 4. Install Python Dependencies
```sh
pip install -r requirements.txt
```

### 5. (Optional) Set up API Keys
- For OpenAI (gpt-3.5-turbo-0125): set `OPENAI_API_KEY` in your environment or a `.env` file.
- For Gemini (gemini-1.5-flash-8b): set `GEMINI_API_KEY` in your environment or a `.env` file.

### 6. Run Setup
```sh
python -m src.ragmh.cli setup --source counselchat
```

---

## Usage
### Query the system
```sh
python -m src.ragmh.cli query "How to deal with anxiety?" --llm ollama
python -m src.ragmh.cli query "How to deal with anxiety?" --llm gpt-3.5-turbo-0125
python -m src.ragmh.cli query "How to deal with anxiety?" --llm gemini-1.5-flash-8b
```

### Interactive chat
```sh
python -m src.ragmh.cli chat
```

### Evaluation Pipeline
To evaluate system outputs (semantic similarity, context relevance, response quality, toxicity):
```sh
python tests/eval_pipeline.py --file <log_or_results.json>
```
- Logs are saved in `data/logs/` by default.
- Evaluation results are saved as `<logfile>_eval_results.json`.

### Compare Command
- The `compare` command is currently **unavailable**. To restore, re-implement `compare_with_vanilla_llm` in `chains.py` and wire it up in the CLI.

---

## Enhancements & Features
- **Prompt engineering** and **response post-processing** are applied throughout the pipeline (see `src/ragmh/quick_rag_fixes.py`).
- **Context reranking** uses a cross-encoder for improved relevance.
- **Evaluation** includes semantic similarity, context relevance, and toxicity checks.
- **Multiple LLM backends**: Ollama (local), OpenAI (gpt-3.5-turbo-0125), Gemini (gemini-1.5-flash-8b).
- **Modular design**: Each pipeline step is a separate module for easy extension.

## Advanced Features

### ğŸ¤– Enhanced Embeddings with Reason-ModernColBERT

The system supports **Reason-ModernColBERT** for enhanced semantic understanding and reasoning capabilities:

```bash
# Generate embeddings with Reason-ModernColBERT
python -m src.ragmh.embed reason

# Generate hybrid embeddings (combines both models)
python -m src.ragmh.embed hybrid

# Use in Streamlit app (add to sidebar)
```

**Benefits for Mental Health RAG:**
- **Enhanced Reasoning**: Better understanding of complex mental health queries
- **Context Awareness**: Improved distinction between symptoms, treatments, and support
- **Empathy Detection**: Better recognition of emotional content and support-seeking language
- **Multi-Source Optimization**: Enhanced retrieval across clinical and community content

**Usage Examples:**
```python
# In your code
from src.ragmh.embed import load_embedding_model, REASON_MODERN_COLBERT

# Load Reason-ModernColBERT
model = load_embedding_model(REASON_MODERN_COLBERT)

# Generate embeddings
embeddings = model.encode(["I'm feeling anxious about my future"])
```

---

## API Key Setup
- Create a `.env` file in the project root with:
```
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...your_key...
```

## Troubleshooting
- If you see errors about missing models or API keys, check your `.env` and ensure Ollama is running.
- For GPU acceleration, ensure you have a compatible version of PyTorch installed.
- If you see `[compare] This feature is currently unavailable...`, see the note above.

## License
MIT